{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # installations\n",
    "\n",
    "# !pip install numpy\n",
    "# !pip install scipy\n",
    "# !pip install math\n",
    "# !pip install scikit-learn\n",
    "# !pip install pandas\n",
    "# !pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleSpec(name='venv', loader=<_frozen_importlib_external.SourceFileLoader object at 0x1106c50d0>, origin='/opt/homebrew/Cellar/python@3.13/3.13.2/Frameworks/Python.framework/Versions/3.13/lib/python3.13/venv/__init__.py', submodule_search_locations=['/opt/homebrew/Cellar/python@3.13/3.13.2/Frameworks/Python.framework/Versions/3.13/lib/python3.13/venv'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib.util as import_util\n",
    "import_util.find_spec('venv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "import math\n",
    "from collections.abc import Sequence\n",
    "\n",
    "# secondary imports\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import Lasso\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bayes VAMP\n",
    "\n",
    "type prior = tuple[str, tuple]\n",
    "# allowed priors: normal, rademacher, 3-point, laplace, bernoulli*normal\n",
    "# params need to be: (tau2, None), None, (p, q), (theta, None), (p, tau2)\n",
    "\n",
    "# compute f = E[beta | beta + N(0, 1/gamma_1) = r]\n",
    "def f_condexp(r_1, gamma_1, prior, prior_params):\n",
    "    \n",
    "    # gaussian: beta_bar ~ N(0, tau^2)\n",
    "    # -----------------------------------------------------------------------------------------\n",
    "    if prior == \"gaussian\":\n",
    "        tau2, _ = prior_params\n",
    "\n",
    "        # closed form solution\n",
    "        f_vals = (tau2 * gamma_1 / (1 + tau2 * gamma_1)) * r_1\n",
    "\n",
    "    # rademacher: beta_bar ~ Uniform{-1, 1}\n",
    "    # -----------------------------------------------------------------------------------------\n",
    "    elif prior == \"rademacher\":\n",
    "        # no prior params\n",
    "        \n",
    "        # closed form solution\n",
    "        f_vals = np.tanh(gamma_1 * r_1)\n",
    "\n",
    "    # three point: beta_bar ~ {-1 : p, 0 : q, 1 : (1 - p-q)}\n",
    "    # -----------------------------------------------------------------------------------------\n",
    "    elif prior == \"three_point\":\n",
    "        theta_1, theta_2 = prior_params\n",
    "\n",
    "        var = 1/max(gamma_1, 1e-12)\n",
    "        \n",
    "        # compute density for the derivative\n",
    "        def marginal_density(r):\n",
    "            return (\n",
    "                theta_1 * scipy.stats.norm.pdf(r, loc = -1, scale = np.sqrt(var))\n",
    "                + theta_2 * scipy.stats.norm.pdf(r, loc = 0, scale = np.sqrt(var))\n",
    "                + (1 - theta_1 - theta_2) * scipy.stats.norm.pdf(r, loc = 1, scale = np.sqrt(var))\n",
    "            )\n",
    "        \n",
    "        # compute derivative for numerator\n",
    "        def density_derivative(r):\n",
    "            return (\n",
    "                -gamma_1 * (theta_1 * scipy.stats.norm.pdf(r, loc = -1, scale = np.sqrt(var)) * (r+1)\n",
    "                + theta_2 * scipy.stats.norm.pdf(r, loc = 0, scale = np.sqrt(var)) * (r)\n",
    "                + (1 - theta_1 - theta_2) * scipy.stats.norm.pdf(r, loc = 1, scale = np.sqrt(var)) * (r-1))\n",
    "            )\n",
    "\n",
    "        # use tweedie's formula \n",
    "        f_vals = r_1 + var * density_derivative(r_1) / (marginal_density(r_1) + 1e-8)\n",
    "\n",
    "\n",
    "    # bernoulli/normal mix: beta_bar ~ bernoulli(theta) * normal(0, tau2)\n",
    "    # -----------------------------------------------------------------------------------------\n",
    "    elif prior == \"bernoulli_gaussian\":\n",
    "        theta, tau2 = prior_params\n",
    "\n",
    "        var = 1/max(gamma_1, 1e-16)\n",
    "        \n",
    "        # compute density for the derivative\n",
    "        def marginal_density(r):\n",
    "            return (1-theta) * scipy.stats.norm.pdf(r, 0, np.sqrt(var)) + theta * scipy.stats.norm.pdf(r, 0, np.sqrt(tau2 + var))\n",
    "        \n",
    "        # compute derivative for the numerator\n",
    "        def density_derivative(r) :\n",
    "            return -((1-theta) * (gamma_1 * r) * scipy.stats.norm.pdf(r, 0, np.sqrt(var)) + theta * (r / (tau2 + var) * scipy.stats.norm.pdf(r, 0, np.sqrt(tau2 + var))))\n",
    "        \n",
    "        # use tweedie's formula\n",
    "        f_vals = r_1 + var * density_derivative(r_1) / (marginal_density(r_1) + 1e-8)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"given prior is not yet supported\")\n",
    "\n",
    "    return f_vals\n",
    "\n",
    "# for f = E[beta | beta + N(0, 1/gamma_1) = r], compute f'(r) wrt r\n",
    "def f_derivative(r_1, gamma_1, prior, prior_params):\n",
    "\n",
    "    # gaussian: beta_bar ~ N(0, tau^2)\n",
    "    # -----------------------------------------------------------------------------------------\n",
    "    if prior == \"gaussian\" :\n",
    "        tau2, _ = prior_params\n",
    "        \n",
    "        # full_like to facilitate return of a vector of values, although constant\n",
    "        return np.full_like(r_1, (gamma_1 * tau2) / (gamma_1 * tau2 + 1))\n",
    "    \n",
    "    # rademacher: beta_bar ~ Uniform{-1, 1}\n",
    "    # -----------------------------------------------------------------------------------------\n",
    "    if prior == \"rademacher\":\n",
    "        if gamma_1 > 128.0 :\n",
    "            return np.zeros(len(r_1))\n",
    "          \n",
    "        return gamma_1 * (1/np.cosh(gamma_1 * r_1)) ** 2\n",
    "    \n",
    "\n",
    "    # three point: beta_bar ~ {-1 : p, 0 : q, 1 : (1 - p-q)}\n",
    "    # -----------------------------------------------------------------------------------------\n",
    "    elif prior == \"three_point\":\n",
    "        theta_1, theta_2 = prior_params\n",
    "        theta_3 = 1 - theta_1 - theta_2\n",
    "\n",
    "        var = 1/max(gamma_1, 1e-12)\n",
    "        \n",
    "        # compute density for the derivative\n",
    "        def marginal_density(r):\n",
    "            return (\n",
    "                theta_1 * scipy.stats.norm.pdf(r, loc = -1, scale = np.sqrt(var))\n",
    "                + theta_2 * scipy.stats.norm.pdf(r, loc = 0, scale = np.sqrt(var))\n",
    "                + (1 - theta_1 - theta_2) * scipy.stats.norm.pdf(r, loc = 1, scale = np.sqrt(var))\n",
    "            )\n",
    "        \n",
    "        # compute derivative for numerator\n",
    "        def density_derivative(r):\n",
    "            return (\n",
    "                -gamma_1 * (theta_1 * scipy.stats.norm.pdf(r, loc = -1, scale = np.sqrt(var)) * (r+1)\n",
    "                + theta_2 * scipy.stats.norm.pdf(r, loc = 0, scale = np.sqrt(var)) * (r)\n",
    "                + (1 - theta_1 - theta_2) * scipy.stats.norm.pdf(r, loc = 1, scale = np.sqrt(var)) * (r-1))\n",
    "            )\n",
    "        \n",
    "        def density_2ndderivative(r) :\n",
    "            return (\n",
    "                -gamma_1 * (theta_1 * scipy.stats.norm.pdf(r, loc = -1, scale = np.sqrt(var)) * (1 - gamma_1 * (r+1)**2) \n",
    "                            + theta_2 * scipy.stats.norm.pdf(r, scale = np.sqrt(var)) * (1 - gamma_1 * r**2) \n",
    "                            + theta_3 * scipy.stats.norm.pdf(r, loc = 1, scale = np.sqrt(var)) * (1 - gamma_1 * (r-1)**2))\n",
    "            )\n",
    "        \n",
    "        f_prime_vals = 1 + var * (density_2ndderivative(r_1) * marginal_density(r_1) - density_derivative(r_1)**2) / np.maximum(marginal_density(r_1)**2, 1e-16)\n",
    "\n",
    "    # bernoulli/normal mix: beta_bar ~ bernoulli(theta) * normal(0, tau2)\n",
    "    # -----------------------------------------------------------------------------------------\n",
    "    elif prior == \"bernoulli_gaussian\":\n",
    "        theta, tau2 = prior_params\n",
    "\n",
    "        var = 1/max(gamma_1, 1e-16)\n",
    "        \n",
    "        # compute density for the derivative\n",
    "        def marginal_density(r):\n",
    "            return (1-theta) * scipy.stats.norm.pdf(r, 0, np.sqrt(var)) + theta * scipy.stats.norm.pdf(r, 0, np.sqrt(tau2 + var))\n",
    "        \n",
    "        # compute derivative for the numerator\n",
    "        def density_derivative(r) :\n",
    "            return -((1-theta) * (gamma_1 * r) * scipy.stats.norm.pdf(r, 0, np.sqrt(var)) + theta * (r / (tau2 + var) * scipy.stats.norm.pdf(r, 0, np.sqrt(tau2 + var))))\n",
    "        \n",
    "        def density_2ndderivative(r) :\n",
    "            return (1 - theta) * scipy.stats.norm.pdf(r, 0, np.sqrt(var)) * (-gamma_1 + (gamma_1 * r)**2) + theta * scipy.stats.norm.pdf(r, 0, np.sqrt(tau2 + var)) * (-1/(tau2 + var) + (r/(tau2 + var))**2)\n",
    "        \n",
    "        f_prime_vals = 1 + var * (density_2ndderivative(r_1) * marginal_density(r_1) - density_derivative(r_1)**2) / np.maximum(marginal_density(r_1)**2, 1e-16)\n",
    "\n",
    "    return f_prime_vals\n",
    "\n",
    "# bvamp_tag\n",
    "def vamp_bayes(X, y, prior_info : Sequence[prior], oracle_sigma2, max_iter = 100, tol = 1e-8, retrieve = False, verbose = False) :\n",
    "\n",
    "    _, p = X.shape\n",
    "    # delta_inv = p / n\n",
    "\n",
    "    prior_name, prior_params = prior_info\n",
    "\n",
    "    # initialization\n",
    "    r_1_k = 0.01 * np.ones(p)\n",
    "    gamma_1_k = 0.05\n",
    "\n",
    "    # empty arrays to store iterates\n",
    "    beta_hat = []\n",
    "    r_1 = []\n",
    "    r_2 = []\n",
    "\n",
    "    # iterate\n",
    "    for k in range(max_iter) :\n",
    "\n",
    "        # add r_1 to storage\n",
    "        r_1.append(r_1_k)\n",
    "\n",
    "        # -----------------------------------------------------------------------------------------\n",
    "\n",
    "        # updates part 1 --- f and f'\n",
    "        \n",
    "        # update beta_hat\n",
    "        beta_hat_k = f_condexp(r_1_k, gamma_1_k, prior_name, prior_params)\n",
    "\n",
    "        if (np.isnan(gamma_1_k)) :\n",
    "            print('uh oh gamma_1k')\n",
    "            return\n",
    "\n",
    "        # update b\n",
    "        b_k = np.mean(f_derivative(r_1_k, gamma_1_k, prior_name, prior_params))\n",
    "\n",
    "        if (np.isnan(b_k)) :\n",
    "            print('uh oh b_k')\n",
    "            return\n",
    "        \n",
    "        # -----------------------------------------------------------------------------------------\n",
    "\n",
    "        # parts where prior doesn't matter\n",
    "        \n",
    "        # update eta 1\n",
    "        eta_1_k = gamma_1_k / (max(b_k, 1e-8))\n",
    "\n",
    "        if (np.isnan(eta_1_k)) :\n",
    "            print('uh oh eta_1k')\n",
    "            return\n",
    "        \n",
    "        # update gamma 2\n",
    "        gamma_2_k = eta_1_k - gamma_1_k\n",
    "\n",
    "        if (np.isnan(gamma_2_k)) :\n",
    "            print('uh oh gamma_2k')\n",
    "            return\n",
    "\n",
    "        # update r_2\n",
    "        r_2_k = (1 / (gamma_2_k + 1e-8)) * (eta_1_k * beta_hat_k - gamma_1_k * r_1_k)\n",
    "\n",
    "        # -----------------------------------------------------------------------------------------\n",
    "        \n",
    "        # append new updates for storage\n",
    "        beta_hat.append(beta_hat_k)\n",
    "        r_2.append(r_2_k)\n",
    "\n",
    "        # convergence conditions\n",
    "        # -----------------------------------------------------------------------------------------\n",
    "\n",
    "        if k > 1 and (1/p * np.linalg.norm(beta_hat[-1] - beta_hat[-2])) < tol :\n",
    "            if verbose :\n",
    "                print(\"converged at iteration \" + str(k))\n",
    "            if retrieve :\n",
    "                return beta_hat, r_1, r_2\n",
    "            else :\n",
    "                return beta_hat[-1]\n",
    "            \n",
    "        if k > 1 :\n",
    "            diff1 = beta_hat_k + np.ones(p)\n",
    "            diff2 = beta_hat_k - np.ones(p)\n",
    "            \n",
    "            deviations = np.min(np.array([diff1, diff2, beta_hat_k]), axis = 0)\n",
    "\n",
    "            if np.mean(deviations) <= 1e-4 :\n",
    "                if verbose :\n",
    "                    print(\"converged at iteration \" + str(k))\n",
    "                if retrieve :\n",
    "                    return beta_hat, r_1, r_2\n",
    "                else :\n",
    "                    return beta_hat[-1]\n",
    "            \n",
    "        # -----------------------------------------------------------------------------------------\n",
    "\n",
    "        # updates part 2, continue\n",
    "        \n",
    "        # update c for gamma_1\n",
    "        inv_arg = np.linalg.inv((1/oracle_sigma2) * X.T @ X + (gamma_2_k+1e-8) * np.eye(p))\n",
    "        c_k = (1/p) * np.trace(gamma_2_k * inv_arg)\n",
    "\n",
    "        if (np.isnan(c_k)) :\n",
    "            print('uh oh c_k')\n",
    "            return\n",
    "\n",
    "        # update gamma_1\n",
    "        gamma_1_k = gamma_2_k * (1/(np.clip(c_k, 1e-12, 1-1e-12)) - 1)\n",
    "\n",
    "        if (np.isnan(gamma_1_k)) :\n",
    "            print('uh oh gamma_1k')\n",
    "            return\n",
    "\n",
    "        # update r_1\n",
    "        r_1_k = (1 / max(1-c_k, 1e-8)) * (inv_arg @ (1/oracle_sigma2 * X.T @ y + gamma_2_k * r_2_k) - c_k * r_2_k)\n",
    "\n",
    "    if retrieve :\n",
    "        return beta_hat, r_1, r_2\n",
    "    \n",
    "    if verbose :\n",
    "        print(\"did not converge early\")\n",
    "        \n",
    "    return beta_hat[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lvamp_tag\n",
    "# VAMP LASSO\n",
    "\n",
    "def vamp_lasso(X, y, reg_lambda = 1, oracle_sigma2 = 1, max_iter = 100, tol = 1e-8, verbose = False, retrieve = False) :\n",
    "\n",
    "    # soft thresholding denoiser for lasso\n",
    "    def soft_threshold(x, threshold):\n",
    "        return np.sign(x) * np.maximum(np.abs(x) - threshold, 0)\n",
    "\n",
    "    def subgradient_soft_threshold(r_1, threshold):\n",
    "        grad = np.zeros_like(r_1)\n",
    "        grad[np.abs(r_1) > threshold] = 1.0\n",
    "        grad[np.isclose(np.abs(r_1), threshold)] = 0.75\n",
    "        \n",
    "        return grad\n",
    "\n",
    "    _, p = X.shape\n",
    "\n",
    "    # initialization\n",
    "    r_1 = np.random.normal(loc = 0, scale = 1, size = p)\n",
    "    gamma_1 = 1\n",
    "\n",
    "    beta_hat_store = []\n",
    "    r_1_store = []\n",
    "    r_2_store = []\n",
    "\n",
    "    # iterate\n",
    "    for _ in range(max_iter) :\n",
    "\n",
    "        r_1_store.append(r_1)\n",
    "        \n",
    "        # update beta_hat\n",
    "        beta_hat = soft_threshold(r_1, reg_lambda / (gamma_1+1e-8))\n",
    "\n",
    "        beta_hat_store.append(beta_hat)\n",
    "\n",
    "        # check divergence\n",
    "        if np.isnan(np.linalg.norm(beta_hat)) :\n",
    "            print(\"divergence\")\n",
    "            return beta_hat\n",
    "\n",
    "        # update b\n",
    "        b = np.mean(subgradient_soft_threshold(r_1, reg_lambda / (gamma_1+1e-8)))\n",
    "\n",
    "        # update eta 1\n",
    "        eta_1 = gamma_1 / (b+1e-8)\n",
    "        \n",
    "        # update gamma 2\n",
    "        gamma_2 = eta_1 - gamma_1\n",
    "\n",
    "        # update r_2\n",
    "        r_2 = (1 /(gamma_2+1e-12)) * (eta_1*beta_hat - gamma_1*r_1)\n",
    "\n",
    "        r_2_store.append(r_2)\n",
    "\n",
    "        # update c for gamma_1\n",
    "        inv_arg = np.linalg.inv((1/oracle_sigma2) * X.T @ X + gamma_2 * np.eye(p))\n",
    "        c = (1/p) * np.trace(gamma_2 * inv_arg)\n",
    "\n",
    "        # update gamma_1\n",
    "        gamma_1 = gamma_2 * (1/(c + 1e-8) - 1)\n",
    "\n",
    "        # update r_1\n",
    "        r_1 = (1 / (1-c + 1e-8)) * (inv_arg @ (1/oracle_sigma2 * X.T @ y + gamma_2*r_2) - c*r_2)\n",
    "\n",
    "    if retrieve :\n",
    "        return beta_hat_store, r_1_store, r_2_store\n",
    "    \n",
    "    return beta_hat_store[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rvamp_tag\n",
    "# VAMP RIDGE\n",
    "\n",
    "def vamp_ridge(X, y, reg_lambda = 1, oracle_sigma2 = 1, max_iter = 100, tol = 1e-8, verbose = False) :\n",
    "\n",
    "    # soft thresholding denoiser for ridge\n",
    "    def l2_shrinkage(x, threshold):\n",
    "        return (1.0 / (1.0 + threshold)) * x\n",
    "\n",
    "    def gradient_shrinkage(x, threshold):\n",
    "        scale = 1.0 / (1.0 + threshold)\n",
    "        return np.full_like(x, scale)\n",
    "\n",
    "    n, p = X.shape\n",
    "    # delta_inv = p / n\n",
    "\n",
    "    # initialization\n",
    "    r_1 = np.random.normal(loc = 0, scale = 1, size = p)\n",
    "    gamma_1 = 1.0\n",
    "\n",
    "    # iterate\n",
    "    for k in range(max_iter) :\n",
    "        \n",
    "        # update beta_hat\n",
    "        beta_hat = l2_shrinkage(r_1, reg_lambda / (gamma_1+1e-12))\n",
    "\n",
    "        # check divergence\n",
    "        if np.isnan(np.linalg.norm(beta_hat)) :\n",
    "            print(\"divergence\")\n",
    "            return beta_hat\n",
    "\n",
    "        # update b\n",
    "        b = np.mean(gradient_shrinkage(r_1, reg_lambda / (gamma_1+1e-12)))\n",
    "\n",
    "        # update eta 1\n",
    "        eta_1 = gamma_1 / (b+1e-12)\n",
    "        \n",
    "        # update gamma 2\n",
    "        gamma_2 = eta_1 - gamma_1\n",
    "\n",
    "        # update r_2\n",
    "        r_2 = (1/ (gamma_2+1e-12)) * (eta_1 * beta_hat - gamma_1 * r_1)\n",
    "\n",
    "        # update c for gamma_1\n",
    "        inv_arg = np.linalg.inv((1/oracle_sigma2) * X.T @ X + (gamma_2+1e-12) * np.eye(p))\n",
    "        c = (1/p) * np.trace(gamma_2 * inv_arg)\n",
    "\n",
    "        # update gamma_1\n",
    "        gamma_1 = gamma_2 * (1/(c+1e-12) - 1)\n",
    "\n",
    "        # update r_1\n",
    "        r_1 = (1 / (1-c + 1e-12)) * (inv_arg @ (1/oracle_sigma2 * X.T @ y + gamma_2*r_2) - c*r_2)\n",
    "\n",
    "    return beta_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cell is the data generation helpers\n",
    "\n",
    "def generate_beta(p, mean = 0.0, var = 1.0, prior = \"gaussian\") :\n",
    "    if prior == \"gaussian\" :\n",
    "        beta = np.random.normal(loc = 0, scale = math.sqrt(var), size = p)\n",
    "\n",
    "    elif prior == \"sparse_gaussian\" :\n",
    "        print(\"not done yet 5\")\n",
    "        \n",
    "    elif prior == \"other\" :\n",
    "        print(\"not done yet 3\")\n",
    "    return beta\n",
    "\n",
    "\n",
    "\n",
    "def generate_gaussian_design(n, p, symmetry = \"asymmetric\") :\n",
    "    if symmetry == \"symmetric\" :\n",
    "        if n != p :\n",
    "            print(\"symmetric matrices need to have same row and column dimensions\")\n",
    "        else :\n",
    "            print(\"not done yet 1\")\n",
    "\n",
    "    elif symmetry == \"asymmetric\" :\n",
    "        matrix = np.random.normal(loc = 0, scale = 1 / math.sqrt(n), size = (n, p))\n",
    "        \n",
    "    else :\n",
    "        print(\"invalid matrix type\")\n",
    "        \n",
    "    return matrix\n",
    "\n",
    "\n",
    "\n",
    "def generate_rri_design(n, p, k = -1, method = \"lnn\") :\n",
    "    if method == \"lnn\" :\n",
    "        if k == -1 :\n",
    "            k = p\n",
    "            \n",
    "        X_1 = np.random.normal(loc = 0, scale = 1, size = (n, k))\n",
    "        X_2 = np.random.normal(loc = 0, scale = 1, size = (k, k))\n",
    "        X_3 = np.random.normal(loc = 0, scale = 1, size = (k, k))\n",
    "        X_4 = np.random.normal(loc = 0, scale = 1, size = (k, p))\n",
    "        \n",
    "        X = (1 / math.sqrt(n)) * X_1 @ X_2 @ X_3 @ X_4\n",
    "\n",
    "    elif method == \"heavy_tail\" :\n",
    "        df = 3\n",
    "        mean = np.zeros(p)\n",
    "        scale = np.eye(p)\n",
    "        X = scipy.stats.multivariate_t.rvs(loc = mean, shape = scale, df = df, size = n)\n",
    "\n",
    "    elif method == \"spiked\" :\n",
    "        X, V, W, signal, noise = generate_spiked(n, p)\n",
    "    \n",
    "    else :\n",
    "        print(\"invalid matrix type\")\n",
    "\n",
    "    return X\n",
    "\n",
    "\n",
    "\n",
    "def generate_response(design_matrix, signal, noise_var) :\n",
    "    n, _ = design_matrix.shape\n",
    "    error = np.random.normal(loc = 0, scale = math.sqrt(noise_var), size = n)\n",
    "\n",
    "    return design_matrix @ signal + error\n",
    "\n",
    "\n",
    "\n",
    "# helper for generating spiked matrix\n",
    "def haar_orthonormal_columns(n, m):\n",
    "    G = np.random.normal(size = (n, m))\n",
    "    Q, R = np.linalg.qr(G)\n",
    "    \n",
    "    signs = np.sign(np.diag(R))\n",
    "    signs[signs == 0] = 1.0\n",
    "    Q = Q * signs[np.newaxis, :]\n",
    "    return Q\n",
    "\n",
    "# helper for spiked matrix generation\n",
    "def generate_spiked(n, p, m = 50, alpha = 10.0, seed = None):\n",
    "    if m > min(n, p):\n",
    "        raise ValueError(\"m must be <= min(n, p)\")\n",
    "    \n",
    "    V = haar_orthonormal_columns(n, m) \n",
    "    W = haar_orthonormal_columns(p, m) \n",
    "\n",
    "    signal = alpha * (V @ W.T)               \n",
    "    noise = (1.0/math.sqrt(n)) * np.random.normal(size = (n, p))\n",
    "\n",
    "    X = signal + noise\n",
    "\n",
    "    return X, V, W, signal, noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for phase transition in 3-point for bayes VAMP.\n",
    "# tagged1\n",
    "\n",
    "delta = 0.8\n",
    "\n",
    "p = 500\n",
    "n = int(delta * p)\n",
    "\n",
    "sigmas2 = [0.01] # [0.001, 0.0025, 0.005, 0.0075, 0.01, 0.0125, 0.015, 0.0175, 0.02, 0.0225, 0.025, 0.0275, 0.03]\n",
    "tau2 = 1\n",
    "\n",
    "theta1 = 0.2\n",
    "theta2 = 0.4\n",
    "\n",
    "mse_bvamp = []\n",
    "mse_lvamp = []\n",
    "\n",
    "for sigma2 in sigmas2 :\n",
    "    errors_bvamp = []\n",
    "    errors_lvamp = []\n",
    "\n",
    "    for _ in range(20) :\n",
    "\n",
    "        # use bernoulli * normal\n",
    "        beta = np.random.choice((-1, 0, 1), p = (theta1, theta2, 1 - theta1 - theta2), size = p)#np.random.binomial(1, theta, size = p) * np.random.normal(0, scale = np.sqrt(tau2), size = p)\n",
    "        prior_info = (\"three_point\", (theta1, theta2))\n",
    "\n",
    "        X = generate_rri_design(n, p, method = \"lnn\")\n",
    "        y = generate_response(X, beta, sigma2)\n",
    "        \n",
    "        lambda_lvamp = 0.1\n",
    "\n",
    "        estimate_bvamp = vamp_bayes(X, y, prior_info, oracle_sigma2 = sigma2)\n",
    "\n",
    "        if not np.all(np.isnan(np.linalg.norm(estimate_bvamp - beta))) :\n",
    "            errors_bvamp.append(1/p * np.linalg.norm(estimate_bvamp - beta) ** 2)\n",
    "    \n",
    "    mse_bvamp.append(np.median(errors_bvamp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.float64(0.01561818968878742)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_bvamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for phase transition in 3-point for bayes VAMP.\n",
    "# tagged1\n",
    "\n",
    "delta = 0.8\n",
    "\n",
    "p = 500\n",
    "n = int(delta * p)\n",
    "\n",
    "sigmas2 = [0.01] # [0.001, 0.0025, 0.005, 0.0075, 0.01, 0.0125, 0.015, 0.0175, 0.02, 0.0225, 0.025, 0.0275, 0.03]\n",
    "tau2 = 1\n",
    "\n",
    "theta = 0.3\n",
    "\n",
    "theta1 = 0.2\n",
    "theta2 = 0.4\n",
    "\n",
    "mse_bvamp = []\n",
    "mse_lvamp = []\n",
    "\n",
    "for sigma2 in sigmas2 :\n",
    "    errors_bvamp = []\n",
    "    errors_lvamp = []\n",
    "\n",
    "    for _ in range(20) :\n",
    "\n",
    "        # use bernoulli * normal\n",
    "        beta = np.random.binomial(1, theta, size = p) * np.random.normal(0, scale = np.sqrt(tau2), size = p) # np.random.choice((-1, 0, 1), p = (theta1, theta2, 1 - theta1 - theta2), size = p)#\n",
    "        prior_info = (\"bernoulli_gaussian\", (theta, tau2))\n",
    "\n",
    "        X = generate_rri_design(n, p, method = \"lnn\")\n",
    "        y = generate_response(X, beta, sigma2)\n",
    "        \n",
    "        lambda_lvamp = 0.1\n",
    "\n",
    "        estimate_bvamp = vamp_bayes(X, y, prior_info, oracle_sigma2 = sigma2)\n",
    "\n",
    "        if not np.all(np.isnan(np.linalg.norm(estimate_bvamp - beta))) :\n",
    "            errors_bvamp.append(1/p * np.linalg.norm(estimate_bvamp - beta) ** 2)\n",
    "    \n",
    "    mse_bvamp.append(np.median(errors_bvamp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.float64(0.007306725264257463)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_bvamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
